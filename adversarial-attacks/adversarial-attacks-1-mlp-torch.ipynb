{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f0ed7e",
   "metadata": {},
   "source": [
    "## Atelier pratique : attaques adversariales - 1\n",
    "\n",
    "Impl√©mentation guid√©e d‚Äôune attaque adversariale. <br>\n",
    "Attaques :  **FGSM** et **PGD** <br>\n",
    "Mod√®le cible : un petit mod√®le d‚Äôimage fait √† la main sur MNIST <br>\n",
    "Framework : PyTorch <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4448f",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Importer les d√©pendances de PyTorch.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459d576",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Utiliser `torch`, `torch.nn`, `torch.optim`, `torchvision`, `torchvision.transforms`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8360d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/1_imports.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d1fe7",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Charger le dataset MNIST √† partir de torchvision.datasets.MNIST.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4016dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afca44",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Utiliser un DataLoader de `torch.utils.data`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aafea49",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/2_data_loader.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e6640",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">D√©finir un petit CNN destin√© √† classer les images de MNIST.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22188cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d3b8c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Une architecture Conv2d ‚Üí ReLU ‚Üí Linear suffit. <br>\n",
    "D√©finir une classe h√©ritant de nn.Module. <br>\n",
    "Dans l'__init__, cr√©er une couche Conv2d ainsi qu'une couche Linear, en suivant bien les tailles des objets manipul√©s. <br>\n",
    "Dans le forward, appliquer ces √©tapes ainsi qu'un flatten plac√© au bon endroit (exemple de syntaxe : x.view(x.size(0), -1)).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7f502",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/3_simple-cnn.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbcbd6",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Instancier le mod√®le (et l'envoyer sur le device). Instancier √©galement les outils (une fonction de perte et un optimizer classiques).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d218437",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ....to(device) # ‚úèÔ∏è √† compl√©ter\n",
    "criterion = ... # ‚úèÔ∏è √† compl√©ter\n",
    "optimizer = ... # ‚úèÔ∏è √† compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c651f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Pour un probl√®me de classification multiclasse, la fonction de perte standard est CrossEntropyLoss. <br>\n",
    "Utiliser par exemple comme optimizer Adam avec un taux d'apprentissage de 0.001.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f953f2a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/4_instanciation.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1f4ce",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Effectuer un entra√Ænement rapide.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in ...: # ‚úèÔ∏è √† compl√©ter\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.... # ‚úèÔ∏è √† compl√©ter\n",
    "        outputs = ... # ‚úèÔ∏è √† compl√©ter\n",
    "        loss = # ‚úèÔ∏è √† compl√©ter\n",
    "        ... # ‚úèÔ∏è √† compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2eb9f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Dans la boucle interne, on r√©cup√®re deux √©l√©ments donn√©s par un it√©rable PyTorch g√©n√©ralement utilis√© pour charger des mini‚Äëbatches. <br>\n",
    "Avant le calcul du gradient, une op√©ration essentielle doit √™tre faite pour √©viter l‚Äôaccumulation des gradients d‚Äôune it√©ration √† l‚Äôautre (PyTorch les accumule par d√©faut). <br>\n",
    "Faire une passe directe (forward). <br>\n",
    "Un outil cr√©√© lors de l‚Äôinitialisation de l‚Äôentra√Ænement sert √† comparer les pr√©dictions aux labels, cr√©ant un tenseur scalaire. <br>\n",
    "Backpropagation. <br>\n",
    "Mise √† jour des poids.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa77ec",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/5_training.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43011be7",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Impl√©menter l'attaque FGSM.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, ...):  # ‚úèÔ∏è √† compl√©ter\n",
    "    images = images.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    outputs = ... # ‚úèÔ∏è √† compl√©ter\n",
    "    loss = ... # ‚úèÔ∏è √† compl√©ter\n",
    "    \n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss.... # ‚úèÔ∏è √† compl√©ter\n",
    "    \n",
    "    adv_images = torch.clamp(..., ..., ...) # ‚úèÔ∏è √† compl√©ter\n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a0e1c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "FGSM : epsilon * sign(gradient) <br>\n",
    "Les calculs d'output et de loss sont-ils diff√©rents de ceux de l'entra√Ænement ? <br>\n",
    "O√π rajouter la perturbation ? <br>\n",
    "torch.clamp(image, min, max) sert √† \"forcer\" les valeurs d‚Äôun tenseur dans un intervalle donn√©. L‚Äôajout de perturbations peut faire d√©passer les bornes. Quelles sont les bornes dans notre cas ? Ici nous sommes en convention float.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe7878",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/6_fgsm.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130b94c",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Impl√©menter l'attaque PGD.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, epsilon, alpha, iters):\n",
    "\n",
    "    ori_images = images.clone().detach()\n",
    "    # model.eval()  # optionnel, cf remarque\n",
    "\n",
    "    for _ in range(iters):\n",
    "        images = images.clone().detach().requires_grad_(True)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            outputs = ... # ‚úèÔ∏è √† compl√©ter\n",
    "            loss = ... # ‚úèÔ∏è √† compl√©ter\n",
    "\n",
    "        # ‚úèÔ∏è √† compl√©ter\n",
    "\n",
    "    return images.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a094a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Repartir de la syntaxe de FGSM et g√©rer la boucle d'it√©rations suppl√©mentaire.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b391a2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/7_pgd.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5cf01",
   "metadata": {},
   "source": [
    "Selon votre impl√©mentation, il peut y avoir quelques diff√©rences avec l'attaque r√©elle PGD. <br>\n",
    "La solution pr√©sent√©e pr√©sente quelques possibilit√©s d'am√©liorations pour tendre vers un PGD r√©el :\n",
    "- l'initialisation se fait souvent (de mani√®re al√©atoire) dans la boule L<sub>‚àû</sub>(œµ) au d√©part (x<sub>0</sub> = x + uniform(-Œµ, Œµ)),\n",
    "- PGD peut √™tre g√©n√©ralis√© √† d‚Äôautres normes (classiquement L<sub>2</sub> et L<sub>1</sub>),\n",
    "- alpha peut √™tre exprim√© en fonction de œµ (classiquement alpha ‚âà Œµ / iters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978e220",
   "metadata": {},
   "source": [
    "Enfin, une remarque : dans les v√©ritables attaques it√©ratives, on utilise g√©n√©ralement model.eval() pour s‚Äôassurer que chaque it√©ration de l‚Äôattaque (et non les it√©rations d‚Äôentra√Ænement comme les batchs ou les epochs) voit exactement le m√™me mod√®le. <br>\n",
    "Pour notre SimpleCNN, cela ne change rien, mais avec un mod√®le au comportement stochastique (en particulier lorsqu‚Äôil contient des couches Dropout ou BatchNorm) cela devient utile. <br>\n",
    "Sans model.eval(), chaque it√©ration de PGD serait effectu√©e avec un mod√®le l√©g√®rement diff√©rent, ce qui rend les gradients incoh√©rents d‚Äôune it√©ration √† l‚Äôautre et diminue l‚Äôefficacit√© de l‚Äôattaque.\n",
    "\n",
    "https://github.com/ultralytics/yolov5/issues/12808"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869edb6",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Question bonus si vous √™tes en avance : impl√©menter l'attaque PGD en L<sub>2</sub> plut√¥t que L<sub>‚àû</sub>.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce799982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54640f9",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Tester et comparer les attaques FGSM et PGD.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391aa618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecf7ac",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Choisir une valeur de Œµ.\n",
    "It√©rer sur le jeu de test (le Loader associ√©).\n",
    "G√©n√©rer les attaques adverses sur les images de test.\n",
    "R√©aliser la classification √† l'aide du mod√®le attaqu√©.\n",
    "Calculer la pr√©cision associ√©e.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3348b7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/8_comparaison.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88dba1",
   "metadata": {},
   "source": [
    "Une premi√®re version simplifi√©e de l'attaque **Carlini & Wagner** a √©t√© impl√©ment√©e et est fournie dans le bloc suivant. <span style=\"color: orange;\">Est-elle performante ?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cw_l22_attack(model, images, labels, c=1e-3, kappa=0, lr=0.01, iters=50):\n",
    "    model.eval()\n",
    "    batch_size = images.size(0)\n",
    "\n",
    "    # tanh-space transform\n",
    "    imgs_tanh = torch.atanh(images * 2 - 1)\n",
    "    w = imgs_tanh.detach().clone().requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([w], lr=lr)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get adversarial image\n",
    "        adv = torch.tanh(w)\n",
    "        adv = (adv + 1) / 2  # back to [0,1]\n",
    "\n",
    "        # compute logits\n",
    "        logits = model(adv)\n",
    "\n",
    "        # correct class and max other class logits\n",
    "        true_logit = logits.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
    "        max_other_logit = torch.max(\n",
    "            logits.masked_fill(\n",
    "                torch.nn.functional.one_hot(labels, logits.size(1)).bool(), \n",
    "                -1e9\n",
    "            ), dim=1\n",
    "        )[0]\n",
    "\n",
    "        # CW objective f(x)\n",
    "        f = torch.clamp(max_other_logit - true_logit + kappa, min=0)\n",
    "\n",
    "        # L2^2 loss\n",
    "        l2 = torch.sum((adv - images) ** 2, dim=[1,2,3])\n",
    "\n",
    "        loss = l2 + c * f\n",
    "        loss = loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    adv = torch.tanh(w)\n",
    "    return (adv + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fc37879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed5ba8c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Lui faire subir le m√™me sort qu'aux deux attaques pr√©c√©dentes et comparer les performances.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f923b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/9_cw_simplifie.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb2289",
   "metadata": {},
   "source": [
    "L'impl√©mentation nous para√Æt peu efficace. Nous allons utiliser une librairie d√©di√©e pour effectuer une vraie attaque CW.\n",
    "\n",
    "<span style=\"color: orange;\">Installer la librairie **Torchattacks** :</span>\n",
    "\n",
    "```bash\n",
    "pip install torchattacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697be40",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Gr√¢ce √† Torchattacks, appliquer l'attaque CW. Evaluer son efficacit√© et la comparer √† celle de notre CW manuel ainsi qu'√† celle des autres attaques.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b326abc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "Utiliser la classe `torchattacks.CW`.\n",
    "\n",
    "\n",
    "Exemple d‚Äôutilisation :\n",
    "```python\n",
    "atk = torchattacks.CW(model, c=1e-3, lr=0.01, steps=50)\n",
    "adv = atk(images, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e4d84",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/10_torchattacks_cw.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba495f4a",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Torchattacks est-elle une librairie s√©rieuse ? Appliquer son impl√©mentation de PGD.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271732e9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Indice</summary>\n",
    "CW devrait vous donner une id√©e de la classe √† utiliser pour appliquer PGD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3092c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/11_torchattacks_pgd.py)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642fa3f",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Donner une conclusion possible √† ce TP.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e3c9f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/12_conclusion.txt)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43359302",
   "metadata": {},
   "source": [
    "<span style=\"color: orange;\">Question bonus : ces attaques ont-elles besoin de conna√Ætre le vrai label de l'image ?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bfc96",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üíª Voir la solution</summary>\n",
    "\n",
    "üëâ [Solution](./_solutions/tp1/13_connaissance-label.txt)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416825e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
